Goal: â€œTo evaluate model recommendations using historical userâ€“item interactions.â€

Dataset: Describe what data youâ€™re using (e.g., movie ratings, clicks, etc.).

Split: Chronological (train before test to prevent leakage).

Metrics: Choose 2â€“3 metrics such as Precision@10, Recall@10, MAP, NDCG.

Evaluation Procedure: Describe how predictions are ranked and compared.

Output: Results stored in results/offline_eval.json.

ğŸ“ Code: scripts/offline_eval.py  
ğŸ“ Config: config/eval_config.yaml
